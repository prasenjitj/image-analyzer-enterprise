# Enterprise Image Analyzer - Production Ready

> **üìã Status Update - Repository Restructuring Complete ‚úÖ**  
> All issues from the recent repository restructuring have been identified and fixed:
> - ‚úÖ Server startup path issues resolved  
> - ‚úÖ Missing directories auto-created
> - ‚úÖ Security vulnerabilities patched
> - ‚úÖ All functionality tested and verified working
> 
> **üöÄ Ready to Use**: `python3 server/run_server.py` now starts successfully!  
> See [UPDATED_QUICK_START_GUIDE.md](UPDATED_QUICK_START_GUIDE.md) for details.

A scalable, production-ready image analysis system capable of processing millions of images with advanced queuing, batch management, and real-time monitoring.

## üöÄ Features

- **Massive Scale Processing**: Handle millions of image URLs efficiently  
- **Intelligent Batching**: Process images in configurable chunks with progress tracking
- **PostgreSQL + Redis**: Persistent storage with high-performance caching
- **Background Workers**: Parallel processing with automatic retry logic
- **Real-time Dashboard**: Live progress tracking and system metrics
- **Multi-format Export**: CSV, JSON, Excel exports with filtering
- **RESTful API**: Complete programmatic access to all features
- **Fault Tolerance**: Automatic error recovery and pause/resume support

## üìã Quick Start (5 minutes)

For full, step-by-step setup with screenshots and troubleshooting, see QUICK_START.md.

### Prerequisites
- Python 3.8+
- PostgreSQL 12+
- Redis 6+
- Google Gemini API keys

### Environment Variables

Key environment variables (full list in [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md#required-environment-variables)):

```bash
# API Keys
GEMINI_API_KEYS=key1,key2,key3          # Comma-separated API keys

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/image_analyzer

# Redis
REDIS_URL=redis://localhost:6379/0

# Application
SECRET_KEY=your_secret_key_here
MAX_UPLOAD_SIZE=104857600               # 100MB in bytes
```

### Setup
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure environment
cp .env.example .env
# Edit .env with your PostgreSQL, Redis, and API credentials

# 3. Initialize database
python setup.py --init-db

# 4. Verify setup
python setup.py --health-check

# 5. Start the application (Local Development)
python3 server/run_server.py

# For production/container deployment
python3 server/run_server_cloud.py

# In another terminal: Start background workers (optional - auto-started)
python server/run_workers.py
```

**Access Dashboard**: http://localhost:5001

## üìñ Documentation

| Document | Purpose |
|----------|---------|
| **[QUICK_START.md](docs/QUICK_START.md)** | Detailed setup and first batch guide |
| **[API_DOCUMENTATION.md](docs/API_DOCUMENTATION.md)** | Complete API reference |
| **[DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)** | Production deployment instructions |
| **[GCP_DEPLOYMENT_GUIDE.md](docs/GCP_DEPLOYMENT_GUIDE.md)** | Google Cloud Platform deployment guide |
| **[PERFORMANCE_OPTIMIZATION_GUIDE.md](docs/PERFORMANCE_OPTIMIZATION_GUIDE.md)** | Performance optimization and scaling strategies |
| **[GCP_FREE_DEPLOYMENT_GUIDE.md](docs/GCP_FREE_DEPLOYMENT_GUIDE.md)** | Free tier GCP deployment guide |

## üöÄ Deployment Scripts

For quick GCP deployment, use the provided bash scripts:

```bash
# Complete automated deployment
./scripts/deploy_all.sh [VM_IP] [PROJECT_ID] [REGION]

# Or run individual steps:
./scripts/create_env_yaml.sh [VM_IP] [PROJECT_ID]
./scripts/create_dockerfiles.sh
./scripts/setup_vpc_connector.sh [PROJECT_ID] [REGION]
./scripts/build_and_deploy_server.sh [PROJECT_ID] [REGION]
./scripts/build_and_deploy_worker.sh [PROJECT_ID] [REGION]
```

## üéØ Common Tasks

### Upload and Process Images
```bash
# Via Web UI
1. Open http://localhost:5001
2. Drag & drop CSV file with URLs
3. Click "Create Batch"

# Via API
curl -X POST http://localhost:5001/api/v1/batches \
  -F "file=@urls.csv" \
  -F "batch_name=My Batch"
```

### Monitor Progress
```bash
# Web dashboard: http://localhost:5001
# Or via API:
curl http://localhost:5001/api/v1/batches/{batch_id}/status
```

### Export Results
```bash
# Web UI: Click Export dropdown on batch detail page
# Or via API:
curl -O "http://localhost:5001/api/v1/batch-data/export?format=csv"
```

## üèóÔ∏è Architecture

```
src/
‚îú‚îÄ‚îÄ enterprise_app.py          # Flask web server
‚îú‚îÄ‚îÄ background_worker.py       # Batch processing workers
‚îú‚îÄ‚îÄ batch_manager.py           # Batch orchestration
‚îú‚îÄ‚îÄ job_queue.py              # Redis queue management
‚îú‚îÄ‚îÄ export_api.py             # Export functionality
‚îú‚îÄ‚îÄ polling_api.py            # Real-time status API
‚îú‚îÄ‚îÄ database_models.py        # PostgreSQL schema
‚îú‚îÄ‚îÄ export_manager.py         # Export formats
‚îú‚îÄ‚îÄ cache.py                  # Caching layer
‚îú‚îÄ‚îÄ processor.py              # Image processing logic
‚îî‚îÄ‚îÄ enterprise_config.py      # Configuration management

server/
‚îú‚îÄ‚îÄ run_server.py             # Local development server
‚îú‚îÄ‚îÄ run_server_cloud.py       # Container/Cloud Run server
‚îú‚îÄ‚îÄ run_workers.py            # Background worker launcher
‚îú‚îÄ‚îÄ run_worker_cloud.py       # Cloud worker launcher
‚îî‚îÄ‚îÄ run_worker_http.py        # HTTP worker service

scripts/
‚îú‚îÄ‚îÄ deploy_all.sh             # Complete deployment automation
‚îú‚îÄ‚îÄ build_and_deploy_server.sh # Server deployment
‚îú‚îÄ‚îÄ build_and_deploy_worker.sh # Worker deployment
‚îú‚îÄ‚îÄ create_env_yaml.sh        # Environment configuration
‚îî‚îÄ‚îÄ setup_vpc_connector.sh    # VPC network setup

templates/
‚îú‚îÄ‚îÄ modern_enterprise_dashboard.html  # Main UI
‚îú‚îÄ‚îÄ modern_admin_dashboard.html       # Admin panel
‚îú‚îÄ‚îÄ modern_system_status.html         # System metrics
‚îî‚îÄ‚îÄ shared-ui-components.css          # Shared styles
```

## ‚ö° Performance (Updated with Optimizations)

**Single API Key**: ~60 URLs/min | 15M URLs ‚âà 173 days  
**4 API Keys (Optimized)**: ~240 URLs/min | 15M URLs ‚âà 35 days  
**6+ API Keys (High Performance)**: ~350+ URLs/min | 15M URLs ‚âà 24 days  
**Memory**: ~200MB base + optimized workers with memory monitoring

See [PERFORMANCE_OPTIMIZATION_GUIDE.md](docs/PERFORMANCE_OPTIMIZATION_GUIDE.md) for comprehensive optimization strategies and [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) for basic configuration tips.

## üí∞ Cost Estimation

### Cost Assumptions & Methodology

**Processing Rates** (based on performance benchmarks):
- **1 API Key**: ~60 URLs/minute
- **4 API Keys**: ~240 URLs/minute  
- **6 API Keys**: ~350 URLs/minute
- **8 API Keys**: ~450 URLs/minute

**Cost Components**:
- **Google Gemini AI API**: $0.0018 per image (Vision API pricing)

**Assumptions**:
- 70% success rate (30% retries due to network/API issues)
- US-Central1 region pricing
- Optimized configuration from performance guide

### Cost Breakdown by Volume

#### 1.5 Million Images
**Gemini AI API Cost**: $1,350 (1.5M images √ó $0.0018 √ó 1.3 retries)

#### 2 Million Images
**Gemini AI API Cost**: $1,800 (2M images √ó $0.0018 √ó 1.3 retries)

#### 6 Million Images
**Gemini AI API Cost**: $5,400 (6M images √ó $0.0018 √ó 1.3 retries)

### Cost Optimization Strategies

**Reduce API Costs**:
- Use fewer API keys (slower processing, lower API costs)
- Implement result caching (reduce duplicate API calls)
- Batch requests efficiently to minimize retries
- Monitor API usage and optimize prompts for cost efficiency

**Cost vs Performance Trade-offs**:
- **1.5M images**: Balance cost/performance with 6-8 keys
- **2M images**: Scale up to 8-10 keys for reasonable processing time
- **6M images**: Maximum parallelization needed for continuous operation

**Free Tier Options**:
- **Development/Testing**: $0 using free tier resources
- **Small Production**: <$500 for up to 300K images
- **Enterprise**: Custom pricing available for 10M+ images

### Cost Monitoring

Monitor API costs in real-time using:
```bash
# GCP Billing Dashboard
# View by service and time period

# Cost alerts setup
gcloud billing budgets create my-budget \
  --billing-account=XXXXXX-XXXXXX-XXXXXX \
  --display-name="Image Analyzer Budget" \
  --amount=1000 \
  --threshold-rule=percent=50 \
  --threshold-rule=percent=90 \
  --threshold-rule=percent=100
```

See [GCP_DEPLOYMENT_GUIDE.md](docs/GCP_DEPLOYMENT_GUIDE.md) for detailed cost optimization and [PERFORMANCE_OPTIMIZATION_GUIDE.md](docs/PERFORMANCE_OPTIMIZATION_GUIDE.md) for performance tuning.

## üß™ Testing

```bash
# Run all tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_enterprise_system.py -v

# With coverage
python -m pytest tests/ --cov=src
```

## üîß Troubleshooting

**Database Connection Error**
```bash
psql -h localhost -U postgres -d imageprocessing
# Should connect without errors
```

**Redis Connection Error**
```bash
redis-cli ping
# Should return: PONG
```

**Check System Health**
```bash
python setup.py --health-check
```

For more help, see [QUICK_START.md](QUICK_START.md) troubleshooting section.

## üìû Support

- **System Status**: http://localhost:5001/system/status
- **Health Check**: `python setup.py --health-check`
- **Logs**: `logs/enterprise_app.log`
- **API Docs**: [API_DOCUMENTATION.md](API_DOCUMENTATION.md)

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
